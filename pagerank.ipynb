{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pagerank.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM/jnC1Iu6dy/odbmWCWhUU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tilacyn/ir-itmo/blob/master/pagerank.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5G-N66KjzY28",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "f19c8528-5523-48d8-fa5b-970884cd745c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teodq_bO9EG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dcg(relevance, k=None):\n",
        "  k = len(relevance) if k is None else k\n",
        "  dcg = np.sum(((np.power(2, relevance) - 1) / np.log2(2 + np.arange(len(relevance))))[:k])\n",
        "  return dcg if dcg > 0 else 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRjImpimVork",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import numpy as np\n",
        "from scipy.special import expit\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def preprocess(labels, query_ids):\n",
        "    query_groups = {}\n",
        "    for query_index, query_id in enumerate(query_ids):\n",
        "        l = query_groups.setdefault(query_id, [])\n",
        "        l.append(query_index)\n",
        "\n",
        "    query_idcg = {}\n",
        "    query_permutations = {}\n",
        "    for query_id, query_indexes in query_groups.items():\n",
        "        idcg = dcg(sorted(labels[query_indexes], reverse=True))\n",
        "        query_idcg[query_id] = idcg\n",
        "        query_permutations[query_id] = np.tile(np.arange(len(query_indexes)), (len(query_indexes), 1))\n",
        "\n",
        "    return query_groups, query_idcg, query_permutations\n",
        "\n",
        "\n",
        "class LambdaMartModel:\n",
        "    def __init__(self, lr, n_trees):\n",
        "        self.lr = lr\n",
        "        self.n_trees = n_trees\n",
        "        self.models = []\n",
        "        self.train_loss = []\n",
        "\n",
        "\n",
        "    def newton(self, objects, tree, lambdas, hess):\n",
        "        leaf_index_dct = {}\n",
        "        objects = objects.astype(np.float32)\n",
        "        for sample_index, leaf_index in enumerate(tree.tree_.apply(objects)):\n",
        "            l = leaf_index_dct.setdefault(leaf_index, [])\n",
        "            l.append(sample_index)\n",
        "\n",
        "        for leaf_index, sample_indexes in leaf_index_dct.items():\n",
        "            nom = - lambdas[sample_indexes].sum()\n",
        "            denom = hess[sample_indexes].sum()\n",
        "            if nom == 0 or denom == 0:\n",
        "                tree.tree_.value[leaf_index] = 0.\n",
        "            else:\n",
        "                tree.tree_.value[leaf_index] = nom / denom\n",
        "\n",
        "        return tree\n",
        "\n",
        "\n",
        "    def train(self, objects, labels, predictions):\n",
        "        self.query_groups, self.query_idcg, self.query_permutations = preprocess(labels, predictions)\n",
        "        for i in tqdm(range(self.n_trees)):\n",
        "            model = DecisionTreeRegressor(max_depth=10, max_features='sqrt')\n",
        "            lambdas, hess = self.calc_lambdas(labels, predictions)\n",
        "            model.fit(objects, - lambdas)\n",
        "            model = self.newton(objects, model, lambdas, hess)\n",
        "            self.models.append(model)\n",
        "            predictions += np.int64(self.lr * model.predict(objects))\n",
        "\n",
        "            print('train loss: {}'.format(np.mean(self.train_loss)))\n",
        "\n",
        "\n",
        "    def calc_lambdas(self, y_true, y_pred):\n",
        "        lambdas = np.empty_like(y_true)\n",
        "\n",
        "        loss = 0\n",
        "        idcg = 0\n",
        "        hess = np.empty(len(y_true))\n",
        "        for query_id, query_indexes in self.query_groups.items():\n",
        "            query_y_true = y_true[query_indexes]\n",
        "            query_y_pred = y_pred[query_indexes]\n",
        "            i_j = self.query_permutations[query_id]\n",
        "            i_j_preds = query_y_pred[i_j]\n",
        "            i_j_true = query_y_true[i_j]\n",
        "\n",
        "            document_positions = np.empty_like(query_indexes)\n",
        "            document_positions[np.argsort(-query_y_pred, kind='mergesort')] = np.arange(1, len(query_indexes) + 1)\n",
        "            doc_pos_matrix = np.tile(document_positions, (len(query_indexes), 1))\n",
        "\n",
        "            delta_ndcg = (((np.power(2, query_y_true.reshape(-1, 1)) - np.power(2, i_j_true))\n",
        "                           * (1 / np.log2(1 + document_positions.reshape(-1, 1)) - 1 / np.log2(1 + doc_pos_matrix)))\n",
        "                          / self.query_idcg[query_id])\n",
        "\n",
        "            delta_preds = query_y_pred.reshape(-1, 1) - i_j_preds\n",
        "            perm_mask = query_y_true.reshape(-1, 1) - i_j_true\n",
        "\n",
        "            p_ij = np.zeros_like(delta_preds, dtype=np.float32)\n",
        "            p_ij += expit(-delta_preds) * (perm_mask > 0)\n",
        "            p_ij += expit(delta_preds) * (perm_mask < 0)\n",
        "\n",
        "            lambda_ij = -np.abs(delta_ndcg) * p_ij\n",
        "            query_lambdas = np.sum(lambda_ij * (perm_mask > 0) - lambda_ij * (perm_mask < 0), axis=1)\n",
        "            lambdas[query_indexes] = query_lambdas\n",
        "\n",
        "            loss += dcg(query_y_true[np.argsort(-query_y_pred)], None)\n",
        "            idcg += dcg(sorted(query_y_true, reverse=True), None)\n",
        "\n",
        "            hess[query_indexes] = 1 * np.sum(\n",
        "                np.abs(delta_ndcg) * p_ij * (1 - p_ij) * (perm_mask != 0), axis=1)\n",
        "\n",
        "        self.train_loss.append(loss / idcg)\n",
        "\n",
        "        return lambdas, hess\n",
        "\n",
        "\n",
        "    def predict(self, objects):\n",
        "        preds = np.sum([self.lr * tree.predict(objects) for tree in self.models], axis=0)\n",
        "        return preds\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3WJyJr20mjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from os.path import join as opjoin\n",
        "\n",
        "base_path = '/content/drive/My Drive/ir-itmo/pagerank-ir-itmo'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jo39Y8oxzQlH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(base_path)\n",
        "\n",
        "from sklearn.datasets import load_svmlight_file\n",
        "\n",
        "objects, labels, query_ids = load_svmlight_file('l2r/train.txt', query_id=True)\n",
        "objects = objects.todense()\n",
        "objects = np.asarray(objects)\n",
        "non_zero_columns_mask = objects.sum(0) != 0\n",
        "objects = objects[:, non_zero_columns_mask].astype(np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5-bZUgbzO3l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lambda_mart_model = LambdaMartModel(n_trees=100, lr=0.05)\n",
        "\n",
        "lambda_mart_model.train(objects, labels, query_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfmANvCczA6d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_set, test_labels, query_ids_test = load_svmlight_file('l2r/test.txt', query_id=True)\n",
        "test_set = test_set.todense()\n",
        "test_set = np.asarray(test_set)\n",
        "test_set = test_set[:, non_zero_columns_mask].astype(np.float32)\n",
        "\n",
        "test_output = lambda_mart_model.predict(test_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsGI49ciWQWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "submission = pd.read_csv('l2r/sample.made.fall.2019')\n",
        "\n",
        "submission['QueryId'] = query_ids_test\n",
        "submission['pred'] = test_output\n",
        "submission['DocumentId'] = np.arange(1, submission.shape[0] + 1)\n",
        "\n",
        "submission = submission[['QueryId']].drop_duplicates().merge(submission.sort_values(by=['QueryId', 'pred'], ascending=False))\n",
        "submission = submission[['QueryId', 'DocumentId']]\n",
        "\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}